---
title: Amplicon Matrix Filtering or Pooling, then Correlation with Continuous Sample Metadata
output:
  html_document:
    theme: cerulean
    toc: true
    toc_depth: 1
    toc_float: true
    number_sections: true
params:
  amp_mat_name: &AMPMATNAME NA
  val_cutoff: NA
  sd_cutoff: NA
  tax_rank: NA
  cor_cutoff: 0.5
  cor_method: 'kendall'
  p_adj_method: 'BH'
  p_adj_cutoff: 0.05
#-----------------------------------
  otu_table_flpth: NA
  tax_table_flpth: NA  # flpth or NA. shoult not be empty-type (i.e., all '' or NA) tables 
  metadata_flpth: NA 
  out_dir: NA
#-----------------------------------
  scale: 'raw' # OTU table, one of {raw, ln, log1, log10} ... TODO this is probably not dependable
  mcol: NA # 1-based col index of metadata. col should be numeric
  mname: NA # sample metadata field name
#-----------------------------------
  funcs_flpth: '/kb/module/lib/R/workflow_funcs.R'
  debug: true
---




```{r init, include=FALSE}

library(plotly)
library(phyloseq)
library(knitr)
library(stringr)

knitr::opts_chunk$set(
  echo=FALSE, 
  warning=FALSE, # all warnings will be printed in the console instead of the output document
  message=FALSE, 
  results='asis'
)
options(max.print=60)

```

```{r}

## Flatten Rmd params ##
for(nm in names(params)) {
  if(params[[nm]] == "NA") assign(nm, NA)
  else assign(nm, params[[nm]])
}

################################################################################
###### Hardcode ################################################################
################################################################################
    # amp_mat_name = '<INSERT AMPLICONMATRIX NAME HERE>'
    # cor_cutoff = 0.2
    # cor_method = 'kendall'
    # tax_rank = 'genus'
    # p_adj_cutoff = 0.5
    # mcol = 62
    # funcs_flpth = '~/kbsdk-workspace/OTUSampleMetadataCorrelation/lib/R/workflow_funcs.R'
    # otu_table_flpth =  '~/otu_table.tsv'
    # tax_table_flpth = '~/tax_table.tsv'
    # metadata_flpth = '~/sample_metadata.tsv'
    # out_dir = '~'
    # debug = T
################################################################################
    
    

if(debug) {
keep=c('val_cutoff', 'sd_cutoff', 'tax_rank', 'cor_cutoff', 'cor_method', 'p_adj_method', 'p_adj_cutoff')
paramsdf = stack(params[keep])
paramsdf = data.frame(row.names=paramsdf$ind, arg=paramsdf$values)
kable(paramsdf, caption='Debugging Input Parameters')
}    
    
source(funcs_flpth, local=knitr::knit_global())

```




```{r load_explore}
## Read Files ##

o = phyloseq::otu_table(
  read.table(
    otu_table_flpth, 
    header=TRUE, # col names in 1st line
    sep="\t", 
    check.names=FALSE, # don't check names can be variables (so can start with num)
    row.names=1), 
  taxa_are_rows=TRUE
)
m = phyloseq::sample_data(
  read.table(
    metadata_flpth, header=TRUE, sep='\t', row.names=1
  )[,mcol,drop=FALSE]
)

if(!is.na(tax_table_flpth) & !is.na(tax_rank)) { # checked in wrapper app, but this is better for running manually with hardcodes
  t = phyloseq::tax_table(as.matrix(read.table(tax_table_flpth, header=TRUE, sep='\t', row.names=1)))
  if(is_empty(t)) stop('Empty taxonomy table') # checked in wrapper app
  do_tax = TRUE
  has_tax = TRUE
} else {
  t = NA
  do_tax = FALSE # this means do pooling by taxonomy
  has_tax = FALSE # this means taxonomy information is available 
                                 # TODO differentiate these cases
}


ps = phyloseq(o, t, m)

message(sprintf('DEBUG: %s, %s',dim(o),dim(m)))


```



```{r clean}
## Drop for missing sample metadata ##

old_colnum = nsamples(ps)
ps = prune_samples(!is.na(sample_data(ps))[,1], ps)

n_dropped = old_colnum - nsamples(ps)
if(n_dropped > 0) {
  cat_text(sprintf(
    'Note: %d samples dropped due to missing sample metadata', 
    n_dropped
  ))
}
```       




# Filter or Pool {.tabset .tabset-fade}

```{r}


o = otu_table(ps)

## Max val ##
max_vals = data.frame(max_vals=apply(o, MARGIN=1, function(row) max(row)), row.names=row.names(o))

## Standard deviation ##
stdv = data.frame(stdv=apply(o, MARGIN=1, function(row) sd(row)), row.names=row.names(o))

## Inspect Statistics ##
filtervars = data.frame(max_vals=max_vals$max_vals, stdv=stdv$stdv)
```



## Histogram of Filtering Statistics {.unnumbered}


```{r plotly_hist}
yaxis = list(
  title = "num amplicons"
)
if(dim(filtervars)[1] > 300) {
  yaxis['type'] = 'log'
}

xaxis = list(
  title="max val"
)
fig_max_val = plot_ly(x=filtervars$max_vals, type="histogram") %>% layout(xaxis=xaxis, yaxis=yaxis)

xaxis = list(
  title="stdv"
)
fig_stdv = plot_ly(x=filtervars$stdv, type="histogram") %>% layout(xaxis=xaxis, yaxis=yaxis)

title = list(
  text='Amplicon Filtering Statistics Histograms',
  xref=0
)
margin = list(
  t=70
)
plotly::subplot(fig_max_val, fig_stdv, nrows=2, titleX=T, titleY=T) %>% layout(showlegend=F, title=title, margin=margin)
```


```{r cutoffs}
q = 0.25 # testing purposes
if(is.na(val_cutoff)) val_cutoff = quantile(max_vals$max_vals, q)
if(is.na(sd_cutoff)) sd_cutoff = quantile(stdv$stdv, q)


#dfcut = data.frame(cutoff=c(val_cutoff, sd_cutoff, tax_rank), row.names=c('max_val', 'stdv', 'tax_rank'))
#kable(dfcut, caption='Amplicon filtering cutoffs and taxonomic pooling rank')
```


## Table of Filtering or Pooling Results {.unnumbered .active}

```{r init_droptab}
droptab = data.frame(row.names=c('num amplicons'))
droptab$start = c(ntaxa(ps))
```


```{r filter}

## Try by max val ##
b_keepByMaxVal = filter_taxa(ps, function(row) max(row) > val_cutoff)

## Try by standard deviation ##
b_keepByStdv = filter_taxa(ps, function(row) sd(row) > sd_cutoff)


## Tabulate ##
droptab$'cut off by max val' = c(sum(!b_keepByMaxVal))
droptab$'cut off by stdv' = c(sum(!b_keepByStdv))


## (Prepare to) do actual filtering by all cutoffs ##
b_keep = b_keepByMaxVal & b_keepByStdv

droptab$'cut off by all' = sum(!b_keep)
```

```{r knit_exit_filterAmplicons}
if(sum(!b_keep) == ntaxa(ps)) {
  kable_droptab(droptab)
  knit_exit(big_red('No amplicons passed filtering!'))
}
```

```{r tax_glom}
ps = prune_taxa(b_keep, ps)

ps_ = ps

## Drop for taxonomy ##

if(do_tax) {
  old_rownum = ntaxa(ps)
  ps = tax_glom(
    ps, 
    taxrank=tax_rank, 
    NArm=FALSE, # don't remove amplicons with NA at taxrank
  )
  
  droptab$'reduced by tax pooling' = c(old_rownum-ntaxa(ps))
}


droptab$'remaining' = droptab[1,'start'] - sum(droptab[1,'cut off by all'], droptab[1,'reduced by tax pooling'])
kable(droptab)
```







# Correlate {.tabset .tabset-fade}

```{r}
filterdf = data.frame(
  start=ntaxa(ps),
  check.names=F,
  row.names=c('num amplicons')
)


dmessage('ps before correlation testing')
dmessage(ps)
```

## Table of Filtering Results {.unnumbered}

```{r do_correlation_testing} 

## No more changing ps from here on

cordf = data.frame(row.names=taxa_names(ps))
o = otu_table(ps)
m = sample_data(ps)

if(has_tax) {
  cordf$tax = cat_tax(tax_table(ps))
}

for(anm in taxa_names(ps)) {
  res = cor.test(get_sample(ps,anm), m[[1]], method=cor_method)
  cordf[anm, 'cor'] = res$estimate
  cordf[anm, 'p'] = res$p.value
}
```

```{r knit_exit_succeedCor}
# handle all NA results
keep = rownames(cordf)[complete.cases(cordf)]
toss = rownames(cordf)[!complete.cases(cordf)]

filterdf$'dropped by NA cor' = length(toss)

if(length(keep) == 0) {
  kable(filterdf)
  knit_exit(big_red(
    'Sorry, no amplicons that passed filtering by statistics or pooling by taxonomy succeeded in correlation testing. Not succeeding in correlation testing could be, for example, because of a standard deviation of 0. Please check the correlation formula and the data.'
  ))
}
```


```{r}
dmessage('cordf right after correlation testing')
dmessage(cordf)
```


```{r}
cordf = cordf[keep,]

b_keepByCor = abs(cordf$cor) > cor_cutoff
b_keepByCor[is.na(b_keepByCor)] = FALSE

filterdf$'cut off by cor' = sum(!b_keepByCor)

if(sum(b_keepByCor) == 0) {
  kable(filterdf)
}
```
```{r}
if(sum(b_keepByCor) == 0) {
  knit_exit(big_red('Sorry, no amplicons passed the correlation cutoff.'))
}
```


```{r}
cordf$p_adj = NA
cordf[b_keepByCor,'p_adj'] = p.adjust(cordf[b_keepByCor,'p'], method=p_adj_method)

b_keepByPAdj = cordf$p_adj <= p_adj_cutoff
b_keepByPAdj[is.na(b_keepByPAdj)] = FALSE

# !b_keepByCor is subset of !b_keepByPAdj
filterdf$'cut off by adj p' = sum(!b_keepByPAdj) - sum(!b_keepByCor)

if(sum(b_keepByPAdj) == 0) {
  kable(filterdf)
}
```
```{r}
if(sum(b_keepByPAdj) == 0) {
  knit_exit(big_red('Sorry, no amplicons passed correlation and adjusted p-value cutoffs.'))
}
```


```{r}
cordf = cordf[b_keepByPAdj,] # filter

inds_ordered = order(abs(cordf$cor), decreasing=TRUE)
cordf = cordf[inds_ordered,]

# dmessage(sprintf('INDS_TOP LENGTH: %d', length(inds_top)))
```


```{r filter_table}
filterdf$end = dim(cordf)[1]
kable(filterdf)
```

## Table of Top Amplicons {.unnumbered}



```{r}
kable(cordf, caption='Note: multiple amplicon ids can be collapsed into one when pooling by taxonomy.')
```



## Plot of Top Amplicons {.unnumbered .active}


```{r}
## Determine size of upcoming Rmd figure ##

max_subplots = 20
num_subplots = min(dim(cordf)[1], max_subplots)

c = 2 # num columns
r = ceiling(num_subplots/c) # num rows

w_perPlot = 4.25 # inches
h_perPlot = 3.5 # inches

w_rmd = w_perPlot * c
h_rmd = h_perPlot * r

if(dim(cordf)[1] > max_subplots) {
  cat_text(sprintf('Note: Limiting to top %d plots', max_subplots))
}


dmessage(sprintf('w_rmd: %g', w_rmd))
dmessage(sprintf('h_rmd: %g', h_rmd))
```


```{r plotly, fig.height=h_rmd, fig.width=w_rmd}

figs = list()
for(id in row.names(cordf)[1:num_subplots]) {
  anno = if(do_tax) {
    paste(
      wrap_taxstr(cordf[id,'tax'], len=70), 
      sprintf('cor=%.3g', cordf[id,'cor']), 
      sep='\n'
    ) 
  } else id
  # margin = list(
  #   t=200 # individual margin doesn't work?
  # )
  yaxis = list(
    title=list(
      text='amplicon value',
      standoff=5
    )
  )
  xaxis = list(
    title=list(
      text=colnames(m)[1],
      standoff=5
    )
  )
  fig = plot_ly(
    x=m[[1]],
    y=c(o[id]),
    type='scatter',
    mode='markers',
    size=8, # marker size
    alpha=0.5
  ) %>% 
  layout(yaxis=yaxis, xaxis=xaxis) %>% 
  add_annotations(
    text=anno, 
    x=0.5, 
    y=0.95, 
    xref='paper', 
    yref='paper', 
    xanchor='center', 
    yanchor='top', # top limit of anno
    showarrow=FALSE
  )
  
  figs[[id]] = fig
}

title = list(
  # yref='paper',
  # y=1.01,
  text='Amplicons vs. Sample Metadata'
)
margin = list(
  t=90
)
plotly::subplot(
  figs, 
  nrows=r,
  shareX=FALSE,
  shareY=FALSE, # TRUE -> axis will retain scale but points will go off graph
  titleX=TRUE,
  titleY=TRUE
) %>% layout(title=title, margin=margin, showlegend=FALSE)

```



```{r write, include=FALSE}
### Output results to file
write.table(cordf, file=file.path(out_dir, 'cor.tsv'), sep='\t', quote=FALSE)
```










