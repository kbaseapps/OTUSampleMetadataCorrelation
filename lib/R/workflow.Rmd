---
output:
  html_document:
    theme: cerulean
    number_sections: false
params:
  amp_mat_name: &AMPMATNAME NA
  val_cutoff: NA
  sd_cutoff: NA
  tax_rank: NA
  cor_cutoff: 0.5
  cor_method: 'kendall'
  p_adj_method: 'BH'
  p_adj_cutoff: 0.05
#-----------------------------------
  otu_table_flpth: NA
  tax_table_flpth: NA  # flpth or NA. can not be empty-type (i.e., all '' or NA) tables 
  metadata_flpth: NA 
  out_dir: NA
#-----------------------------------
  scale: 'raw' # OTU table, one of {raw, ln, log1, log10} ... TODO this is probably not dependable
  mcol: NA # 1-based col index of metadata. col should be numeric
  mname: NA # sample metadata field name
#-----------------------------------
  debug: false
---

```{css, echo=FALSE}
h1 {
  display: none;
}

```


```{r init, include=FALSE}

library(plotly)
library(phyloseq)
library(knitr)
library(stringr)

knitr::opts_chunk$set(
  echo=FALSE, 
  warning=FALSE, # all warnings will be printed in the console instead of the output document
  message=FALSE, 
  results='asis'
)
options(max.print=60)

WIDTH_PX = 800 # px
HEIGHT_IN = 6

```

```{r}

## Flatten Rmd params ##
for(nm in names(params)) {
  if(params[[nm]] == "NA") assign(nm, NA)
  else assign(nm, params[[nm]])
}

################################################################################
###### Hardcode ################################################################
################################################################################
    # amp_mat_name = '<INSERT AMPLICONMATRIX NAME HERE>'
    # cor_cutoff = 0.2
    # cor_method = 'kendall'
    # tax_rank = 'genus'
    # p_adj_cutoff = 0.5
    # mcol = 62
    # funcs_flpth = '~/kbsdk-workspace/OTUSampleMetadataCorrelation/lib/R/workflow_funcs.R'
    # otu_table_flpth =  '~/otu_table.tsv'
    # tax_table_flpth = '~/tax_table.tsv'
    # metadata_flpth = '~/sample_metadata.tsv'
    # out_dir = '~'
    # debug = T
################################################################################
    
    

if(debug) {
keep=c('val_cutoff', 'sd_cutoff', 'tax_rank', 'cor_cutoff', 'cor_method', 'p_adj_method', 'p_adj_cutoff')
paramsdf = stack(params[keep])
paramsdf = data.frame(row.names=paramsdf$ind, arg=paramsdf$values)
kable(paramsdf, caption='Debugging Input Parameters')
}    
    
source('/kb/module/lib/R/workflow_funcs.R', local=knitr::knit_global())
source('/kb/module/lib/R/graph_funcs.R', local=knitr::knit_global())
```




```{r load_explore}
## Read Files ##

o = phyloseq::otu_table(
  read.table(
    otu_table_flpth, 
    header=TRUE, # col names in 1st line
    sep="\t", 
    check.names=FALSE, # don't check names can be variables (so can start with num)
    row.names=1), 
  taxa_are_rows=TRUE
)
m = phyloseq::sample_data(
  read.table(
    metadata_flpth, header=TRUE, sep='\t', row.names=1
  )[,mcol,drop=FALSE]
)

if(!is.na(tax_table_flpth) & !is.na(tax_rank)) { # checked in wrapper app, but this is better for running manually with hardcodes
  t = phyloseq::tax_table(as.matrix(read.table(tax_table_flpth, header=TRUE, sep='\t', row.names=1)))
  do_tax = TRUE
  has_tax = TRUE
} else {
  t = NA
  do_tax = FALSE # this means do pooling by taxonomy
  has_tax = FALSE # this means taxonomy information is available. currently taxonomy is ignored if not pooling by 
# TODO differentiate these cases
}


ps = phyloseq(o, t, m)

old_colnum = nsamples(ps)
ps = prune_samples(!is.na(sample_data(ps))[,1], ps)

n_dropped = old_colnum - nsamples(ps)
if(n_dropped > 0) {
  cat_text(sprintf(
    'Note: %d samples dropped due to missing sample metadata', 
    n_dropped
  ))
}
```       




# Dummy Level 1 Header {.tabset .tabset-fade}

## Amplicon Filtering Statistics

```{r}


o = otu_table(ps)

## Max val ##
max_vals = data.frame(max_vals=apply(o, MARGIN=1, function(row) max(row)), row.names=row.names(o))
## Standard deviation ##
stdv = data.frame(stdv=apply(o, MARGIN=1, function(row) sd(row)), row.names=row.names(o))
## Inspect Statistics Later ##
filtervars = data.frame(
  max_vals=max_vals$max_vals, 
  stdv=stdv$stdv
)

q = 0.25 # testing purposes
if(is.na(val_cutoff)) val_cutoff = quantile(max_vals$max_vals, q)
if(is.na(sd_cutoff)) sd_cutoff = quantile(stdv$stdv, q)


droptab = data.frame(row.names=c('Number of amplicons'))
droptab$Start = c(ntaxa(ps))


## Try by max val ##
b_keepByMaxVal = filter_taxa(ps, function(row) max(row) >= val_cutoff)

## Try by standard deviation ##
b_keepByStdv = filter_taxa(ps, function(row) sd(row) >= sd_cutoff)


## Tabulate ##
droptab$'Cut off by max value' = c(sum(!b_keepByMaxVal))
droptab$'Cut off by standard deviation' = c(sum(!b_keepByStdv))


## (Prepare to) do actual filtering by all cutoffs ##
b_keep = b_keepByMaxVal & b_keepByStdv

droptab$'Cut off by all preliminary filtering statistics' = sum(!b_keep)
```


```{r KNIT_EXIT_0_PRELIM_FILTER, fig.height=HEIGHT_IN}
exit_now = sum(!b_keep) == ntaxa(ps)

if(exit_now) do_hists(filtervars, NA) # since do hists won't work in bracketed if body
```
```{r}
if(exit_now) cat_heading('Filtering or Pooling Results')
if(exit_now) {
  print(kable(droptab))
  big_red_exit('No amplicons passed filtering')
}
```


```{r tax_glom}
ps = prune_taxa(b_keep, ps)

## Drop for taxonomy ##

if(do_tax) {
  old_rownum = ntaxa(ps)
  ps = tax_glom(
    ps, 
    taxrank=tax_rank, 
    NArm=FALSE, # don't remove amplicons with NA at taxrank
  )
  
  droptab$'Reduced by taxonomic pooling' = c(old_rownum-ntaxa(ps))
}

## No more changing ps from here on ##
## Use cordf ##

cordf = data.frame(row.names=taxa_names(ps))
o = otu_table(ps)
m = sample_data(ps)

if(has_tax) {
  cordf$tax = cat_tax(tax_table(ps))
}

## Correlation testing ##
for(anm in taxa_names(ps)) {
  res = cor.test(get_sample(ps,anm), m[[1]], method=cor_method)
  cordf[anm, 'cor'] = res$estimate
  cordf[anm, 'p'] = res$p.value
}

# handle all NA results
keep = rownames(cordf)[complete.cases(cordf)]
toss = rownames(cordf)[!complete.cases(cordf)]

cordf = cordf[keep,]

droptab$'Dropped by NA correlation' = length(toss)
```


```{r KNIT_EXIT_1_NA_COR, fig.height=HEIGHT_IN}
exit_now = length(keep) == 0

if(exit_now) do_hists(filtervars, NA)
```
```{r}
if(exit_now) cat_heading('Filtering or Pooling Results')
if(exit_now) {
  print(kable(droptab))
  big_red_exit(
    'No amplicons succeeded in correlation testing. This could be because of division by a standard deviation of 0'
  )
}
```


```{r fig.height=HEIGHT_IN}
do_hists(filtervars, cordf)
```


## Filtering or Pooling Results


```{r}
b_keepByCor = abs(cordf$cor) > cor_cutoff
b_keepByCor[is.na(b_keepByCor)] = FALSE

droptab$'Cut off by correlation' = sum(!b_keepByCor)

```


```{r KNIT_EXIT_2_COR_FILTER}
exit_now = sum(b_keepByCor) == 0

if(exit_now) {
  print(kable(droptab))
  big_red_exit('No amplicons passed filtering')
}
```


```{r}
cordf$p_adj = NA
cordf[b_keepByCor,'p_adj'] = p.adjust(cordf[b_keepByCor,'p'], method=p_adj_method)

b_keepByPAdj = cordf$p_adj <= p_adj_cutoff
b_keepByPAdj[is.na(b_keepByPAdj)] = FALSE

# !b_keepByCor is subset of !b_keepByPAdj
droptab$'Cut off by adjusted p-value' = sum(!b_keepByPAdj) - sum(!b_keepByCor)

```


```{r KNIT_EXIT_3_P_ADJ_FILTER}
exit_now = sum(b_keepByPAdj) == 0
if(exit_now) {
  print(kable(droptab))
  big_red_exit('No amplicons passed correlation and adjusted p-value cutoffs.')
}
```


```{r}
cordf = cordf[b_keepByPAdj,] # filter

inds_ordered = order(abs(cordf$cor), decreasing=TRUE)
cordf = cordf[inds_ordered,]

droptab$End = dim(cordf)[1]
kable(droptab)
```


## Correlation Results



```{r}
cordf_formal = cordf
if(do_tax) {
  colnames(cordf_formal) = c('Taxonomy', 'Correlation', 'P-value', 'Adjusted p-value')
} else {
  colnames(cordf_formal) = c('Correlation', 'P-value', 'Adjusted p-value')
}

kable(
  cordf_formal, 
  row.names=if(do_tax) FALSE else TRUE,
  digits=4,
  format.args=list(scientific=TRUE)
)
```



## Top 10 Amplicons {.active}


```{r}
## Determine size of upcoming Rmd figure ##

max_subplots = 10
num_subplots = min(dim(cordf)[1], max_subplots)

c = 2 # num columns
r = ceiling(num_subplots/c) # num rows

w_perPlot = 3.9 # inches
h_perPlot = 3.5 # inches

w_rmd = w_perPlot * c
h_rmd = h_perPlot * r

#if(dim(cordf)[1] > max_subplots) {
#  cat_text(sprintf('Note: Limiting to top %d plots', max_subplots))
#}


dmessage(sprintf('w_rmd: %g', w_rmd))
dmessage(sprintf('h_rmd: %g', h_rmd))
```



```{r plotly, fig.height=h_rmd, fig.width=w_rmd}
do_scatters(cordf, cor_method, num_subplots, do_tax)

```



```{r write, include=FALSE}
### Output results to file
write.table(cordf, file=file.path(out_dir, 'cor.tsv'), sep='\t', quote=FALSE)
write.table(o, file=file.path(out_dir, 'reduced_amplicon_matrix.tsv'), sep='\t', quote=FALSE)
```









