---
title:
output:
  html_document:
    theme: cerulean
    number_sections: false
params:
  amp_mat_name: &AMPMATNAME NA
  val_cutoff: NA
  sd_cutoff: NA
  tax_rank: NA
  cor_cutoff: 0.5
  cor_method: 'kendall'
  p_adj_method: 'BH'
  p_adj_cutoff: 0.05
#-----------------------------------
  otu_table_flpth: NA
  tax_table_flpth: NA  # flpth or NA. shoult not be empty-type (i.e., all '' or NA) tables 
  metadata_flpth: NA 
  out_dir: NA
#-----------------------------------
  scale: 'raw' # OTU table, one of {raw, ln, log1, log10} ... TODO this is probably not dependable
  mcol: NA # 1-based col index of metadata. col should be numeric
  mname: NA # sample metadata field name
#-----------------------------------
  funcs_flpth: '/kb/module/lib/R/workflow_funcs.R'
  debug: true
---




```{r init, include=FALSE}

library(plotly)
library(phyloseq)
library(knitr)
library(stringr)

knitr::opts_chunk$set(
  echo=FALSE, 
  warning=FALSE, # all warnings will be printed in the console instead of the output document
  message=FALSE, 
  results='asis'
)
options(max.print=60)

WIDTH_PX = 800 # px

```

```{r}

## Flatten Rmd params ##
for(nm in names(params)) {
  if(params[[nm]] == "NA") assign(nm, NA)
  else assign(nm, params[[nm]])
}

################################################################################
###### Hardcode ################################################################
################################################################################
    # amp_mat_name = '<INSERT AMPLICONMATRIX NAME HERE>'
    # cor_cutoff = 0.2
    # cor_method = 'kendall'
    # tax_rank = 'genus'
    # p_adj_cutoff = 0.5
    # mcol = 62
    # funcs_flpth = '~/kbsdk-workspace/OTUSampleMetadataCorrelation/lib/R/workflow_funcs.R'
    # otu_table_flpth =  '~/otu_table.tsv'
    # tax_table_flpth = '~/tax_table.tsv'
    # metadata_flpth = '~/sample_metadata.tsv'
    # out_dir = '~'
    # debug = T
################################################################################
    
    

if(debug) {
keep=c('val_cutoff', 'sd_cutoff', 'tax_rank', 'cor_cutoff', 'cor_method', 'p_adj_method', 'p_adj_cutoff')
paramsdf = stack(params[keep])
paramsdf = data.frame(row.names=paramsdf$ind, arg=paramsdf$values)
}    
    
source(funcs_flpth, local=knitr::knit_global())

```




```{r load_explore}
## Read Files ##

o = phyloseq::otu_table(
  read.table(
    otu_table_flpth, 
    header=TRUE, # col names in 1st line
    sep="\t", 
    check.names=FALSE, # don't check names can be variables (so can start with num)
    row.names=1), 
  taxa_are_rows=TRUE
)
m = phyloseq::sample_data(
  read.table(
    metadata_flpth, header=TRUE, sep='\t', row.names=1
  )[,mcol,drop=FALSE]
)

if(!is.na(tax_table_flpth) & !is.na(tax_rank)) { # checked in wrapper app, but this is better for running manually with hardcodes
  t = phyloseq::tax_table(as.matrix(read.table(tax_table_flpth, header=TRUE, sep='\t', row.names=1)))
  if(is_empty(t)) stop('Empty taxonomy table') # checked in wrapper app
  do_tax = TRUE
  has_tax = TRUE
} else {
  t = NA
  do_tax = FALSE # this means do pooling by taxonomy
  has_tax = FALSE # this means taxonomy information is available. currently taxonomy is ignored if not pooling by
                                 # TODO differentiate these cases
}


ps = phyloseq(o, t, m)

message(sprintf('DEBUG: %s, %s',dim(o),dim(m)))


```



```{r clean}
## Drop for missing sample metadata ##

old_colnum = nsamples(ps)
ps = prune_samples(!is.na(sample_data(ps))[,1], ps)

n_dropped = old_colnum - nsamples(ps)
if(n_dropped > 0) {
  cat_text(sprintf(
    'Note: %d samples dropped due to missing sample metadata', 
    n_dropped
  ))
}
```       




# {- .tabset .tabset-pills .tabset-fade}

```{r}


o = otu_table(ps)

## Max val ##
max_vals = data.frame(max_vals=apply(o, MARGIN=1, function(row) max(row)), row.names=row.names(o))

## Standard deviation ##
stdv = data.frame(stdv=apply(o, MARGIN=1, function(row) sd(row)), row.names=row.names(o))

## Inspect Statistics ##
filtervars = data.frame(max_vals=max_vals$max_vals, stdv=stdv$stdv)
```



## Amplicon Filtering Statistics


```{r plotly_hist}


```


```{r cutoffs}
q = 0.25 # testing purposes
if(is.na(val_cutoff)) val_cutoff = quantile(max_vals$max_vals, q)
if(is.na(sd_cutoff)) sd_cutoff = quantile(stdv$stdv, q)


#dfcut = data.frame(cutoff=c(val_cutoff, sd_cutoff, tax_rank), row.names=c('max_val', 'stdv', 'tax_rank'))
#kable(dfcut, caption='Amplicon filtering cutoffs and taxonomic pooling rank')
```



```{r init_droptab}
droptab = data.frame(row.names=c('Number amplicons'))
droptab$Start = c(ntaxa(ps))
```


```{r filter}

## Try by max val ##
b_keepByMaxVal = filter_taxa(ps, function(row) max(row) >= val_cutoff)

## Try by standard deviation ##
b_keepByStdv = filter_taxa(ps, function(row) sd(row) >= sd_cutoff)


## Tabulate ##
droptab$'Cut off by max value' = c(sum(!b_keepByMaxVal))
droptab$'Cut off by standard deviation' = c(sum(!b_keepByStdv))


## (Prepare to) do actual filtering by all cutoffs ##
b_keep = b_keepByMaxVal & b_keepByStdv

droptab$'Cut off by all preliminary filtering statistics' = sum(!b_keep)
```

```{r knit_exit_filterAmplicons}
if(sum(!b_keep) == ntaxa(ps)) {
  kable_droptab(droptab)
  knit_exit(big_red('No amplicons passed filtering!'))
}
```

```{r tax_glom}
ps = prune_taxa(b_keep, ps)

ps_ = ps

## Drop for taxonomy ##

if(do_tax) {
  old_rownum = ntaxa(ps)
  ps = tax_glom(
    ps, 
    taxrank=tax_rank, 
    NArm=FALSE, # don't remove amplicons with NA at taxrank
  )
  
  droptab$'Reduced by taxonomic pooling' = c(old_rownum-ntaxa(ps))
}


#droptab$'Remaining' = droptab[1,'Start'] - sum(droptab[1,'Cut off by all'], droptab[1,'Reduced by tax pooling'])
#kable(droptab)
```



```{r}
#droptab = data.frame(
#  Start=ntaxa(ps),
#  check.names=F,
#  row.names=c('Number amplicons')
#)


#dmessage('ps before correlation testing')
#dmessage(ps)
```



```{r do_correlation_testing} 

## No more changing ps from here on

cordf = data.frame(row.names=taxa_names(ps))
o = otu_table(ps)
m = sample_data(ps)

if(has_tax) {
  cordf$tax = cat_tax(tax_table(ps))
}

for(anm in taxa_names(ps)) {
  res = cor.test(get_sample(ps,anm), m[[1]], method=cor_method)
  cordf[anm, 'cor'] = res$estimate
  cordf[anm, 'p'] = res$p.value
}
```

```{r knit_exit_succeedCor}
# handle all NA results
keep = rownames(cordf)[complete.cases(cordf)]
toss = rownames(cordf)[!complete.cases(cordf)]

droptab$'Dropped by NA correlation' = length(toss)

if(length(keep) == 0) {
  kable(droptab)
  knit_exit(big_red(
    'Sorry, no amplicons that passed filtering by statistics or pooling by taxonomy succeeded in correlation testing. Not succeeding in correlation testing could be, for example, because of a standard deviation of 0. Please check the correlation formula and the data.'
  ))
}
```


```{r}
dmessage('cordf right after correlation testing')
dmessage(cordf)
```


```{r}
cordf = cordf[keep,]

b_keepByCor = abs(cordf$cor) > cor_cutoff
b_keepByCor[is.na(b_keepByCor)] = FALSE

droptab$'Cut off by correlation' = sum(!b_keepByCor)

if(sum(b_keepByCor) == 0) {
  kable(droptab)
}
```
```{r}
if(sum(b_keepByCor) == 0) {
  knit_exit(big_red('Sorry, no amplicons passed the correlation cutoff.'))
}
```


```{r}
cordf$p_adj = NA
cordf[b_keepByCor,'p_adj'] = p.adjust(cordf[b_keepByCor,'p'], method=p_adj_method)

b_keepByPAdj = cordf$p_adj <= p_adj_cutoff
b_keepByPAdj[is.na(b_keepByPAdj)] = FALSE

# !b_keepByCor is subset of !b_keepByPAdj
droptab$'Cut off by adjusted p-value' = sum(!b_keepByPAdj) - sum(!b_keepByCor)

if(sum(b_keepByPAdj) == 0) {
  kable(droptab)
}
```
```{r}
if(sum(b_keepByPAdj) == 0) {
  knit_exit(big_red('Sorry, no amplicons passed correlation and adjusted p-value cutoffs.'))
}
```


```{r}
cordf = cordf[b_keepByPAdj,] # filter

inds_ordered = order(abs(cordf$cor), decreasing=TRUE)
cordf = cordf[inds_ordered,]

# dmessage(sprintf('INDS_TOP LENGTH: %d', length(inds_top)))
```


```{r}
standoff = 5
font_size = 10


  yaxis = list(
    title=list(
      text='amplicon value',
      font=list(
        size=font_size
      ),
      standoff=5
    )
  )



yaxis = list(
  title=list(
    text='Number amplicons',
    font=list(
      size=font_size
    ),
    standoff=standoff
  )
)
if(dim(filtervars)[1] > 300) {
  yaxis['type'] = 'log'
}

xaxis = list(
  title=list(
    text='Max value',
    font=list(
      size=font_size
    ),
    standoff=standoff
  )
)
fig_max_val = plot_ly(x=filtervars$max_vals, type="histogram") %>% layout(xaxis=xaxis, yaxis=yaxis)

xaxis = list(
  title=list(
    text='Standard deviation',
    font=list(
      size=font_size
    ),
    standoff=standoff
  )
)
fig_stdv = plot_ly(x=filtervars$stdv, type="histogram") %>% layout(xaxis=xaxis, yaxis=yaxis)

xaxis=list(
  title=list(
    text='Correlation',
    font=list(
      size=font_size
    ),
    standoff=standoff
  )
)
fig_cor = plot_ly(x=cordf$cor, type="histogram") %>% layout(xaxis=xaxis, yaxis=yaxis)

# For making spaces between subplots
fig_empty = plotly_empty()
h_empty = 0.08
h_fig = (1-2*h_empty)/3

#title = list(
#  text='Amplicon Filtering Statistics Histograms',
#  xref=0
#)
#margin = list(
#  t=70
#)
plotly::subplot(
  fig_max_val, 
  fig_empty,
  fig_stdv, 
  fig_empty,
  fig_cor,
  nrows=5, 
  heights=c(h_fig,h_empty,h_fig,h_empty,h_fig),
  titleX=T, 
  titleY=T
) %>% 
layout(
  showlegend=F
#  title=title, 
#  margin=margin
)
```

## Filtering or Pooling Results

```{r filter_table}
droptab$End = dim(cordf)[1]
kable(droptab)
```





## Correlation Results



```{r}
cordf_formal = cordf
if(do_tax) {
  colnames(cordf_formal) = c('Taxonomy', 'Correlation', 'P-value', 'Adjusted p-value')
} else {
  colnames(cordf_formal) = c('Correlation', 'P-value', 'Adjusted p-value')
}

kable(
  cordf_formal, 
  caption='Note: multiple amplicon ids can be collapsed into one when pooling by taxonomy.',
  digits=4,
  format.args=list(scientific=TRUE)
)
```



## Top 10 Amplicons {.active}


```{r}
## Determine size of upcoming Rmd figure ##

max_subplots = 10
num_subplots = min(dim(cordf)[1], max_subplots)

c = 2 # num columns
r = ceiling(num_subplots/c) # num rows

w_perPlot = 3.9 # inches
h_perPlot = 3.5 # inches

w_rmd = w_perPlot * c
h_rmd = h_perPlot * r

#if(dim(cordf)[1] > max_subplots) {
#  cat_text(sprintf('Note: Limiting to top %d plots', max_subplots))
#}


dmessage(sprintf('w_rmd: %g', w_rmd))
dmessage(sprintf('h_rmd: %g', h_rmd))
```



```{r plotly, fig.height=h_rmd, fig.width=w_rmd}
if (cor_method == 'kendall') {
  sym = 'τ'
} else if (cor_method == 'pearson') {
  sym = 'r'
} else if (cor_method == 'spearman') {
  sym = 'ρ'
}
sym = paste0('<i>', sym, '</i>')

font_size = 10

figs = list()
for(id in row.names(cordf)[1:num_subplots]) {
  anno = if(do_tax) wrap_taxstr(cordf[id,'tax'], len=65) else id
  anno = paste(
    anno, 
    sprintf('%s = %.3g', sym, cordf[id,'cor']), 
    sep='\n'
  )
  anno = paste('<b>', anno, '</b>')
#  margin = list(
#    t=200 # individual margin doesn't work?
#  )
  yaxis = list(
    title=list(
      text='amplicon value',
      font=list(
        size=font_size
      ),
      standoff=5
    )
  )
  xaxis = list(
    title=list(
      text=colnames(m)[1],
      font=list(
        size=font_size
      ),
      standoff=5
    )
  )
  fig = plot_ly(
    x=m[[1]],
    y=c(o[id]),
    type='scatter',
    mode='markers',
    size=8, # marker size
    alpha=0.5
  ) %>% 
  layout(yaxis=yaxis, xaxis=xaxis) %>% 
  add_annotations(
    text=anno, 
    x=0.5, 
    y=1.05, 
    xref='paper', 
    yref='paper', 
    xanchor='center', 
    yanchor='top', # y is top limit of anno
    showarrow=FALSE,
    font=list(
      size=font_size
    )
  )
  
  figs[[id]] = fig
}

#title = list(
#   yref='paper',
#   y=1.01,
#  text='Amplicons vs. Sample Metadata'
#)
margin = list(
#  t=90
#  t=10,
#  b=3,
  l=10,
  r=10
)
plotly::subplot(
  figs, 
  nrows=r,
  shareX=FALSE,
  shareY=FALSE, # TRUE -> axis will retain scale but points will go off graph
  titleX=TRUE,
  titleY=TRUE
) %>% layout(
#  title=title, 
  margin=margin, # for parent figure
  showlegend=FALSE
)

```



```{r write, include=FALSE}
### Output results to file
write.table(cordf, file=file.path(out_dir, 'cor.tsv'), sep='\t', quote=FALSE)
write.table(o, file=file.path(out_dir, 'reduced_amplicon_matrix.tsv'), sep='\t', quote=FALSE)
```


```{r}
if (debug) kable(paramsdf, caption='Debugging Input Parameters')
```







